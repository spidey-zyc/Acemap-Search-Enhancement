import pandas as pd
from difflib import get_close_matches

# ---------------------------------------------------------
# é…ç½®ï¼šä½ çš„ Parquet æ–‡ä»¶è·¯å¾„
PARQUET_PATH = "data/gakg_subset.parquet" 
# ---------------------------------------------------------

def inspect_parquet():
    """
    åŠŸèƒ½ 1: æŸ¥çœ‹ Parquet æ–‡ä»¶å†…éƒ¨ç»“æ„
    """
    print("\n" + "="*50)
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶: {PARQUET_PATH}")
    print("="*50)
    
    try:
        # engine='pyarrow' æ˜¯è¯»å– parquet çš„å…³é”®
        df = pd.read_parquet(PARQUET_PATH, engine='pyarrow')
        
        print(f"âœ… è¯»å–æˆåŠŸï¼æ•°æ®é›†å…±æœ‰ {len(df)} è¡Œæ•°æ®ã€‚")
        print("\n[ æ•°æ®é¢„è§ˆ (å‰ 5 è¡Œ) ]")
        print(df.head().to_markdown(index=False)) # æ‰“å°æ¼‚äº®çš„è¡¨æ ¼
        
        print("\n[ åˆ—ä¿¡æ¯ ]")
        print(df.info())
        
        return df
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        print("ğŸ’¡ æç¤º: è¯·ç¡®ä¿ä½ å®‰è£…äº† pyarrow (pip install pyarrow)")
        # å¦‚æœæ²¡æœ‰çœŸå®æ–‡ä»¶ï¼Œè¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿçš„ DataFrame ç”¨äºæ¼”ç¤º
        return create_mock_dataframe()

def create_mock_dataframe():
    """åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿæ•°æ®ï¼Œé˜²æ­¢æŠ¥é”™ï¼Œæ–¹ä¾¿æ¼”ç¤º"""
    print("\nâš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
    data = {
        'subject': ['Igneous rock', 'Granite', 'Basalt', 'Sedimentary basin', 'Plate tectonics'],
        'relation': ['is_a', 'is_a', 'is_a', 'related_to', 'related_to'],
        'object': ['Rock', 'Igneous rock', 'Igneous rock', 'Geology', 'Geophysics'],
        'paperid': [1001, 1002, 1003, 1004, 1005]
    }
    return pd.DataFrame(data)

def visualize_impact(df_kg):
    """
    åŠŸèƒ½ 2: ç›´è§‚å±•ç¤ºæ„å›¾åˆ†æå‰åçš„åŒºåˆ«
    """
    print("\n" + "="*50)
    print("ğŸ§  æ„å›¾åˆ†ææ•ˆæœæ¨¡æ‹Ÿ (Before vs After)")
    print("="*50)

    # 1. å‡†å¤‡çŸ¥è¯†åº“è¯è¡¨
    vocab = set(df_kg['subject'].unique()) | set(df_kg['object'].unique())
    
    # 2. æ¨¡æ‹Ÿå‡ ä¸ªç”¨æˆ·çš„æŸ¥è¯¢åœºæ™¯ (åŒ…å«æ‹¼å†™é”™è¯¯)
    test_cases = [
        # (Case 1) æ‹¼å†™é”™è¯¯: Grnite -> Granite
        {"query": "æ‰¾ä¸€ä¸‹ MIT å…³äº Grnite çš„è®ºæ–‡", "llm_raw": ["Grnite", "MIT"]},
        # (Case 2) æ¨¡ç³Šè¾“å…¥: Basalt -> Basalt (æ— éœ€ä¿®æ”¹)
        {"query": "å¸®æˆ‘æ‰¾ Basalt ç›¸å…³çš„ç ”ç©¶", "llm_raw": ["Basalt"]},
        # (Case 3) ä¸¥é‡æ‹¼å†™é”™è¯¯: Sedimentary bsin -> Sedimentary basin
        {"query": "å…³äº Sedimentary bsin çš„æ–‡ç« ", "llm_raw": ["Sedimentary bsin"]}
    ]
    
    results = []
    
    # 3. è¿è¡Œ "KG æ ¡å‡†" é€»è¾‘
    for case in test_cases:
        raw_kws = case['llm_raw']
        grounded_kws = []
        status_log = []
        
        for kw in raw_kws:
            # æ¨¡æ‹Ÿ KG æŸ¥æ‰¾ (ç®€å•æ¨¡ç³ŠåŒ¹é…)
            matches = get_close_matches(kw, vocab, n=1, cutoff=0.7)
            
            if kw == "MIT": # å‡è®¾è¿™æ˜¯æœºæ„ï¼Œä¸åœ¨åœ°è´¨å›¾è°±é‡Œ
                grounded_kws.append(kw)
                continue
                
            if matches:
                fixed_word = matches[0]
                grounded_kws.append(fixed_word)
                if fixed_word != kw:
                    status_log.append(f"ğŸ› ï¸ ä¿®æ­£: {kw} -> {fixed_word}")
            else:
                grounded_kws.append(kw) # æ²¡æ‰¾åˆ°ï¼Œä¿æŒåŸæ ·
        
        results.append({
            "User Query (ç”¨æˆ·è¾“å…¥)": case['query'],
            "ğŸ”´ Before (LLMç›´å‡º)": str(raw_kws),
            "ğŸŸ¢ After (KGå¢å¼º)": str(grounded_kws),
            "âœ¨ æ•ˆæœ": ", ".join(status_log) if status_log else "-"
        })

    # 4. æ‰“å°å¯¹æ¯”è¡¨æ ¼
    df_res = pd.DataFrame(results)
    print(df_res.to_markdown(index=False))

if __name__ == "__main__":
    # 1. çœ‹æ•°æ®
    df = inspect_parquet()
    
    # 2. çœ‹æ•ˆæœ
    if df is not None:
        visualize_impact(df)